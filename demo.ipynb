{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import regex as re\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import os\n",
    "import stat\n",
    "import numpy as np\n",
    "\n",
    "uid = \"raunaqjabbal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_api_key = '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'\n",
    "headers = {\n",
    "    'Accept': 'application/vnd.github+json',\n",
    "    'Authorization': f'Bearer {github_api_key}',\n",
    "    'X-GitHub-Api-Version': '2022-11-28',\n",
    "}\n",
    "\n",
    "response = requests.get(f'https://api.github.com/users/{uid}/repos', headers=headers)\n",
    "response = json.loads(response.text)\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I'm glad you think so! Babies can be adorable with their tiny features and innocent expressions.\"]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "message_list=[{\"role\": \"user\", \"content\": \"The baby is so cute!\"}]\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"model\": \"gpt-3.5-turbo\",\n",
    "    \"temperature\": 0.9,\n",
    "    \"messages\": message_list\n",
    "}\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer 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\"\n",
    "}\n",
    "\n",
    "\n",
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=data)\n",
    "response_json = response.json()\n",
    "\n",
    "if response.status_code == 200:\n",
    "    content = [choice['message']['content'] for choice in response_json['choices']]\n",
    "    print(content)\n",
    "else:\n",
    "    raise Exception(f\"Request failed with status code {response.status_code}: {response_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in response:\n",
    "    if i['fork']== False:\n",
    "        data.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:00<00:00, 13.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to read Repository, Skipping CADVLSI-Project\n",
      "Unable to read Repository, Skipping CancerInstanceSegmentation\n",
      "Unable to read Repository, Skipping ClothingSimilaritySearch\n",
      "Unable to read Repository, Skipping ConditonalGAN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 6/15 [00:00<00:00, 15.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to read Repository, Skipping EvolutionaryAlgorithms\n",
      "Unable to read Repository, Skipping Google-Data-Analytics-Capstone-Project\n",
      "Unable to read Repository, Skipping GTNCode\n",
      "Unable to read Repository, Skipping IBM-Data-Analyst-Capstone-Project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 12/15 [00:00<00:00, 15.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to read Repository, Skipping IBM-Data-Science-Capstone-Project\n",
      "Unable to read Repository, Skipping JHU-Data-Science-Capstone-Project\n",
      "Unable to read Repository, Skipping LinearRegression\n",
      "Unable to read Repository, Skipping MathProblemCategorization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 15.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to read Repository, Skipping NeuralStyleTransfer\n",
      "Unable to read Repository, Skipping raunaqjabbal\n",
      "Unable to read Repository, Skipping Specturm-Sensing-ML\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from git import Repo\n",
    "for i in tqdm(data):\n",
    "    try:\n",
    "        Repo.clone_from(i['clone_url'], os.path.join(os.getcwd(), uid, i['name']))\n",
    "    except:\n",
    "        print(\"Unable to read Repository, Skipping\", i[\"name\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CADVLSI-Project',\n",
       " 'CancerInstanceSegmentation',\n",
       " 'ClothingSimilaritySearch',\n",
       " 'ConditonalGAN',\n",
       " 'EvolutionaryAlgorithms',\n",
       " 'Google-Data-Analytics-Capstone-Project',\n",
       " 'GTNCode',\n",
       " 'IBM-Data-Analyst-Capstone-Project',\n",
       " 'IBM-Data-Science-Capstone-Project',\n",
       " 'JHU-Data-Science-Capstone-Project',\n",
       " 'LinearRegression',\n",
       " 'MathProblemCategorization',\n",
       " 'NeuralStyleTransfer',\n",
       " 'raunaqjabbal',\n",
       " 'Specturm-Sensing-ML']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:19<00:00,  1.33s/it]\n"
     ]
    }
   ],
   "source": [
    "from subprocess import run\n",
    "import subprocess\n",
    "solutions=[]\n",
    "\n",
    "for i in tqdm(os.listdir(uid)):\n",
    "    # output = run(f\"cloc {os.path.join(uid,i)}\", capture_output=True).stdout.decode()\n",
    "    \n",
    "    output = subprocess.getstatusoutput(f\"cloc {os.path.join(uid,i)}\")\n",
    "    if output[0]==0:\n",
    "        solutions.append(parse_cloc_output(output[1], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\n",
    "for i in solutions:\n",
    "\n",
    "    for key, value in i['Summary'].items():\n",
    "        # print(f\"{key}: {value}\")\n",
    "        query+= f\"{key}: {value}\\n\"\n",
    "        \n",
    "    query+= \"\\nLanguage Breakdown:\\n\"\n",
    "    for lang, info in i['Language Breakdown'].items():\n",
    "        query+= f\"{lang}: Files- {info['Files']}, Blank- {info['Blank']}, Comment- {info['Comment']}, Code- {info['Code']}\\n\"\n",
    "    # print(\"\\n\\n\\n\\n\")\n",
    "    query+= \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Name: CADVLSI-Project\\nTotal Files: 100\\nUnique Files: 134\\nIgnored Files: None\\n\\nLanguage Breakdown:\\nC++: Files- 12, Blank- 31706, Comment- 13, Code- 181043\\nCSV: Files- 2, Blank- 0, Comment- 0, Code- 50250\\nAda: Files- 3, Blank- 2, Comment- 0, Code- 41321\\nLLVM IR: Files- 6, Blank- 184, Comment- 128, Code- 12426\\nXML: Files- 19, Blank- 1801, Comment- 0, Code- 9847\\nC/C++ Header: Files- 22, Blank- 840, Comment- 262, Code- 3749\\nVHDL: Files- 17, Blank- 348, Comment- 194, Code- 3749\\nVerilog-SystemVerilog: Files- 17, Blank- 385, Comment- 182, Code- 2384\\nTcl/Tk: Files- 20, Blank- 127, Comment- 75, Code- 1912\\nJSON: Files- 1, Blank- 1, Comment- 0, Code- 649\\nC: Files- 3, Blank- 82, Comment- 27, Code- 246\\nmake: Files- 2, Blank- 36, Comment- 12, Code- 76\\nJupyter Notebook: Files- 1, Blank- 0, Comment- 307, Code- 37\\nPython: Files- 2, Blank- 10, Comment- 14, Code- 33\\nText: Files- 3, Blank- 2, Comment- 0, Code- 29\\nD: Files- 2, Blank- 0, Comment- 0, Code- 24\\nBourne Shell: Files- 1, Blank- 0, Comment- 0, Code- 7\\nDOS Batch: Files- 1, Blank- 0, Comment- 0, Code- 1\\n\\n\\nName: CancerInstanceSegmentation\\nTotal Files: 4\\nUnique Files: 4\\nIgnored Files: None\\n\\nLanguage Breakdown:\\nJupyter Notebook: Files- 3, Blank- 0, Comment- 1409, Code- 353\\nMarkdown: Files- 1, Blank- 10, Comment- 0, Code- 10\\n\\n\\nName: ClothingSimilaritySearch\\nTotal Files: 13\\nUnique Files: 8\\nIgnored Files: None\\n\\nLanguage Breakdown:\\nCSV: Files- 2, Blank- 0, Comment- 0, Code- 18986\\nJupyter Notebook: Files- 2, Blank- 0, Comment- 512, Code- 127\\nPython: Files- 1, Blank- 15, Comment- 2, Code- 42\\nMarkdown: Files- 1, Blank- 5, Comment- 0, Code- 19\\nText: Files- 1, Blank- 0, Comment- 0, Code- 10\\nDockerfile: Files- 1, Blank- 5, Comment- 10, Code- 7\\n\\n\\nName: ConditonalGAN\\nTotal Files: 2\\nUnique Files: 2\\nIgnored Files: None\\n\\nLanguage Breakdown:\\nJupyter Notebook: Files- 1, Blank- 0, Comment- 816, Code- 410\\nMarkdown: Files- 1, Blank- 0, Comment- 0, Code- 1\\n\\n\\nName: EvolutionaryAlgorithms\\nTotal Files: 9\\nUnique Files: 7\\nIgnored Files: None\\n\\nLanguage Breakdown:\\nPython: Files- 6, Blank- 130, Comment- 26, Code- 485\\nMarkdown: Files- 1, Blank- 1, Comment- 0, Code- 1\\n\\n\\nName: Google-Data-Analytics-Capstone-Project\\nTotal Files: 2\\nUnique Files: 1\\nIgnored Files: None\\n\\nLanguage Breakdown:\\nJupyter Notebook: Files- 1, Blank- 0, Comment- 1851, Code- 91\\n\\n\\nName: GTNCode\\nTotal Files: 17\\nUnique Files: 14\\nIgnored Files: None\\n\\nLanguage Breakdown:\\nPython: Files- 5, Blank- 104, Comment- 131, Code- 404\\nMarkdown: Files- 2, Blank- 11, Comment- 0, Code- 29\\nINI: Files- 1, Blank- 4, Comment- 0, Code- 26\\nTOML: Files- 1, Blank- 5, Comment- 0, Code- 21\\nText: Files- 2, Blank- 0, Comment- 0, Code- 11\\nJupyter Notebook: Files- 3, Blank- 0, Comment- 3, Code- 0\\n\\n\\nName: IBM-Data-Analyst-Capstone-Project\\nTotal Files: 8\\nUnique Files: 7\\nIgnored Files: None\\n\\nLanguage Breakdown:\\nJupyter Notebook: Files- 7, Blank- 0, Comment- 6911, Code- 285\\n\\n\\nName: IBM-Data-Science-Capstone-Project\\nTotal Files: 12\\nUnique Files: 11\\nIgnored Files: None\\n\\nLanguage Breakdown:\\nCSV: Files- 3, Blank- 0, Comment- 0, Code- 555\\nJupyter Notebook: Files- 7, Blank- 0, Comment- 3856, Code- 265\\nPython: Files- 1, Blank- 11, Comment- 17, Code- 66\\n\\n\\nName: JHU-Data-Science-Capstone-Project\\nTotal Files: 1\\nUnique Files: 1\\nIgnored Files: None\\n\\nLanguage Breakdown:\\nMarkdown: Files- 1, Blank- 2, Comment- 0, Code- 3\\n\\n\\nName: LinearRegression\\nTotal Files: 7\\nUnique Files: 5\\nIgnored Files: None\\n\\nLanguage Breakdown:\\nPython: Files- 4, Blank- 31, Comment- 63, Code- 138\\nMarkdown: Files- 1, Blank- 1, Comment- 0, Code- 1\\n\\n\\nName: MathProblemCategorization\\nTotal Files: 4\\nUnique Files: 3\\nIgnored Files: None\\n\\nLanguage Breakdown:\\nMarkdown: Files- 1, Blank- 21, Comment- 0, Code- 18\\nJupyter Notebook: Files- 2, Blank- 0, Comment- 2, Code- 0\\n\\n\\nName: NeuralStyleTransfer\\nTotal Files: 2\\nUnique Files: 2\\nIgnored Files: None\\n\\nLanguage Breakdown:\\nJupyter Notebook: Files- 1, Blank- 0, Comment- 549, Code- 181\\nMarkdown: Files- 1, Blank- 0, Comment- 0, Code- 1\\n\\n\\nName: raunaqjabbal\\nTotal Files: 1\\nUnique Files: 1\\nIgnored Files: None\\n\\nLanguage Breakdown:\\nMarkdown: Files- 1, Blank- 4, Comment- 12, Code- 1\\n\\n\\nName: Specturm-Sensing-ML\\nTotal Files: 100\\nUnique Files: 100\\nIgnored Files: None\\n\\nLanguage Breakdown:\\nCSV: Files- 66, Blank- 0, Comment- 0, Code- 1056969\\nTeX: Files- 12, Blank- 495, Comment- 211, Code- 1846\\nPython: Files- 6, Blank- 289, Comment- 240, Code- 1683\\nMATLAB: Files- 13, Blank- 477, Comment- 2842, Code- 1528\\nText: Files- 2, Blank- 8, Comment- 0, Code- 44\\nMarkdown: Files- 1, Blank- 0, Comment- 0, Code- 1\\n\\n\\n'"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cloc_output(output, name):\n",
    "    output = re.sub(' +', ' ', output)\n",
    "    output = re.sub('\\r', '\\n', output)\n",
    "    output = output.strip().split('\\n')\n",
    "    lines=[]\n",
    "    lines = [line.strip() if line != '' else None for line in lines]\n",
    "    \n",
    "    for line in output:\n",
    "        if line!=\"\":\n",
    "            lines.append(line.strip())\n",
    "    \n",
    "    \n",
    "    total_files = int(lines[0].split()[0])\n",
    "    unique_files = None\n",
    "    ignored_files = None\n",
    "    \n",
    "    idx = 0\n",
    "    \n",
    "    for i in range(len(lines)):\n",
    "        x = lines[i].split()\n",
    "        if len(x)>=2 and x[1] == \"unique\":\n",
    "            unique_files = int(x[0])\n",
    "        if len(x)>=3 and x[2] == \"ignored\":\n",
    "            ignored_files = int(x[0])\n",
    "        if lines[i].startswith(\"-\"):\n",
    "            if idx == 0:\n",
    "                idx = i\n",
    "            else:\n",
    "                idx = i+1\n",
    "                break\n",
    "             \n",
    "    lang_breakdown = {}\n",
    "    for line in range(idx, len(lines)):\n",
    "        if lines[line].startswith(\"-\"):\n",
    "            break\n",
    "        lang_info = lines[line].split()\n",
    "        lang_name = \" \".join(lang_info[0:-4])\n",
    "        lang_data = {\n",
    "            'Files': int(lang_info[-4]),\n",
    "            'Blank': int(lang_info[-3]),\n",
    "            'Comment': int(lang_info[-2]),\n",
    "            'Code': int(lang_info[-1])\n",
    "        }\n",
    "        lang_breakdown[lang_name] = lang_data\n",
    "\n",
    "    \n",
    "    return {\n",
    "        'Summary': {\n",
    "            'Name': name,\n",
    "            'Total Files': total_files,\n",
    "            'Unique Files': unique_files,\n",
    "            'Ignored Files': ignored_files\n",
    "        },\n",
    "        'Language Breakdown': lang_breakdown\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmtree(top):\n",
    "    for root, dirs, files in os.walk(top, topdown=False):\n",
    "        for name in files:\n",
    "            filename = os.path.join(root, name)\n",
    "            os.chmod(filename, stat.S_IWUSR)\n",
    "            os.remove(filename)\n",
    "        for name in dirs:\n",
    "            os.rmdir(os.path.join(root, name))\n",
    "    os.rmdir(top)      \n",
    "    \n",
    "rmtree(uid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
